{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6893997",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6eb63532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\ML_Projects_iNeuron\\\\iNeuron_Project_Census_data_Classification_With_MLflow\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a335b5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\ML_Projects_iNeuron\\\\iNeuron_Project_Census_data_Classification_With_MLflow'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Data_preprocessing_ValidationConfig:\n",
    "    root_dir: Path\n",
    "    STATUS_FILE: str\n",
    "    unzip_data_dir: Path\n",
    "    all_schema: dict\n",
    "    Preprocess_data: Path\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b26f69e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Mlflow_Ineuron_Project.constants import *\n",
    "from Mlflow_Ineuron_Project.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "        schema_filepath = SCHEMA_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    \n",
    "    def get_data_validation_config(self) -> Data_preprocessing_ValidationConfig:\n",
    "        config = self.config.data_validation\n",
    "        schema = self.schema.COLUMNS\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "        create_directories([config.preprocess_data_path])\n",
    "\n",
    "        data_validation_config = Data_preprocessing_ValidationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            STATUS_FILE=config.STATUS_FILE,\n",
    "            unzip_data_dir = config.unzip_data_dir,\n",
    "            all_schema=schema,\n",
    "            Preprocess_data=config.preprocess_data_path\n",
    "            \n",
    "        )\n",
    "\n",
    "        return data_validation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from Mlflow_Ineuron_Project import logger\n",
    "from  sklearn.preprocessing import LabelEncoder,OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_preprocessing_Validation:\n",
    "    def __init__(self, config: Data_preprocessing_ValidationConfig):\n",
    "        self.config = config\n",
    "\n",
    "\n",
    "    def data_transformer_object(self):\n",
    "        try:\n",
    "            numerical_col=['age','fnlwgt', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "\n",
    "            categorical_col=['workclass', 'education', 'marital-status', 'occupation', 'sex', 'country']\n",
    "            \n",
    "       \n",
    "            # pipeline for numerical columns\n",
    "            # handling the \n",
    "            Numeric_pipeline=Pipeline(\n",
    "                steps=[\n",
    "                    (\"imputer\",SimpleImputer(strategy=\"mean\"))\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            Categorical_pipeline=Pipeline(\n",
    "               steps= [\n",
    "                    (\"imputer\",SimpleImputer(strategy=\"most_frequent\")), \n",
    "                    # (\"lowercase\", lowercase_transformer),  # Convert text to lowercase\n",
    "                    (\"onehot_encoder\",OrdinalEncoder())\n",
    "                    ]\n",
    "            )\n",
    "\n",
    "            # logging.info(f\"categorical Columns: {categorical_col}\")\n",
    "            # logging.info(\"pipeline is created for the Column and numeric column transformation\")\n",
    "\n",
    "\n",
    "            preprocessor=ColumnTransformer(\n",
    "                [\n",
    "                    (\"Numeric_pipeline\",Numeric_pipeline,numerical_col),\n",
    "                    (\"Categorical_pipeline\",Categorical_pipeline,categorical_col),\n",
    "                    # (\"target_pipeline\",target_pipeline,target_col)\n",
    "\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            return preprocessor\n",
    "        except Exception as e:\n",
    "            raise e   \n",
    "\n",
    "    def validate_all_columns(self)-> bool:\n",
    "        try:\n",
    "            validation_status = None\n",
    "\n",
    "            data = pd.read_csv(self.config.unzip_data_dir)\n",
    "       # remove the extra space around the columns \n",
    "            data.columns=data.columns.str.strip()\n",
    "            categorical_col = ['workclass', 'education', 'marital-status', 'occupation', 'sex', 'country', 'salary']\n",
    "            for col in categorical_col:\n",
    "                if col in data.columns:\n",
    "                    data[col] = data[col].str.strip()\n",
    "\n",
    "            numerical_col=['age','fnlwgt', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "\n",
    "            categorical_col=['workclass', 'education', 'marital-status', 'occupation', 'sex', 'country','salary']\n",
    "            # # for col in categorical_col:\n",
    "            #     if col in data.columns:\n",
    "            #         data[col] = data[col].str.lower()\n",
    "            #     if col in data.columns:\n",
    "            #         data[col] = data[col].str.lower() \n",
    "            # print(data.head())\n",
    "            data.drop(columns=['relationship', 'race','education-num'], inplace=True)\n",
    "            preprocessor_object=self.data_transformer_object()\n",
    "            output=data\n",
    "            output=preprocessor_object.fit_transform(data)\n",
    "            # label encoding \n",
    "            for i in categorical_col:\n",
    "                le=LabelEncoder()\n",
    "                data[i]=le.fit_transform(data[i])\n",
    "            print(data.head(1))\n",
    "\n",
    "            all_cols = list(data.columns)\n",
    "\n",
    "            all_schema = self.config.all_schema.keys()\n",
    "\n",
    "            print(all_schema)\n",
    "            for col in all_cols:\n",
    "                # print(col)\n",
    "                if col not in all_schema:\n",
    "                    validation_status = False\n",
    "                    with open(self.config.STATUS_FILE, 'w') as f:\n",
    "                        f.write(f\"Validation status: {validation_status}\")\n",
    "                else:\n",
    "                    validation_status = True\n",
    "                    with open(self.config.STATUS_FILE, 'w') as f:\n",
    "                        f.write(f\"Validation status: {validation_status}\")\n",
    "\n",
    "            joblib.dump(preprocessor_object,os.path.join(self.config.Preprocess_data,\"Preprocess_model.joblib\"))\n",
    "            data.to_csv(os.path.join(self.config.Preprocess_data,\"preprocessed_data.csv\"),index=False)\n",
    "\n",
    "            return validation_status\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85cbafec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-23 14:14:37,821: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-04-23 14:14:37,821: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-04-23 14:14:37,836: INFO: common: yaml file: schema.yaml loaded successfully]\n",
      "[2025-04-23 14:14:37,836: INFO: common: created directory at: artifacts]\n",
      "[2025-04-23 14:14:37,844: INFO: common: created directory at: artifacts/data_validation]\n",
      "[2025-04-23 14:14:37,847: INFO: common: created directory at: artifacts/data_preprocessed]\n",
      "   age  workclass  fnlwgt  education  marital-status  occupation  sex  \\\n",
      "0   39          7   77516          9               4           1    1   \n",
      "\n",
      "   capital-gain  capital-loss  hours-per-week  country  salary  \n",
      "0          2174             0              40       39       0  \n",
      "dict_keys(['age', 'workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'country', 'salary'])\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_validation_config = config.get_data_validation_config()\n",
    "    data_validation =Data_preprocessing_Validation(config=data_validation_config)\n",
    "    data_validation.validate_all_columns()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "124be135",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "model=joblib.load('artifacts\\data_preprocessed\\Preprocess_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9c0a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data1=pd.read_csv('E:\\\\ML_Projects_iNeuron\\\\iNeuron_Project_Census_data_Classification_With_MLflow\\\\artifacts\\\\data_ingestion\\\\Census_dataset.csv')\n",
    "# data1.columns=data1.columns.str.strip()\n",
    "# categorical_col=['workclass', 'education', 'marital-status', 'occupation', 'sex', 'country']\n",
    "# data1.drop(columns=['relationship', 'race','education-num'], inplace=True)\n",
    "# # for col in categorical_col:\n",
    "# #     if col in data1.columns:\n",
    "# #         data1[col] = data1[col].str.lower()\n",
    "# #     if col in data1.columns:\n",
    "# #         data1[col] = data1[col].str.lower() \n",
    "# # output=model.transform(data1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89e7fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  workclass  fnlwgt  education  education-num marital-status  \\\n",
      "0   39  State-gov   77516  Bachelors             13  Never-married   \n",
      "\n",
      "     occupation    relationship    race   sex  capital-gain  capital-loss  \\\n",
      "0  Adm-clerical   Not-in-family   White  Male          2174             0   \n",
      "\n",
      "   hours-per-week        country salary  \n",
      "0              40  United-States  <=50K  \n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# data1=pd.read_csv('E:\\\\ML_Projects_iNeuron\\\\iNeuron_Project_Census_data_Classification_With_MLflow\\\\artifacts\\\\data_ingestion\\\\Census_dataset.csv')\n",
    "\n",
    "# categorical_col = ['workclass', 'education', 'marital-status', 'occupation', 'sex', 'country', 'salary']\n",
    "# for col in categorical_col:\n",
    "#     if col in data1.columns:\n",
    "#         data1[col] = data1[col].str.strip()\n",
    "\n",
    "# print(data1.head(1))\n",
    "# # print(\"Columns rearranged successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8633dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.90000e+01 7.75160e+04 2.17400e+03 0.00000e+00 4.00000e+01 7.00000e+00\n",
      "  9.00000e+00 4.00000e+00 1.00000e+00 1.00000e+00 3.90000e+01]\n",
      " [5.00000e+01 8.33110e+04 0.00000e+00 0.00000e+00 1.30000e+01 6.00000e+00\n",
      "  9.00000e+00 2.00000e+00 4.00000e+00 1.00000e+00 3.90000e+01]\n",
      " [3.80000e+01 2.15646e+05 0.00000e+00 0.00000e+00 4.00000e+01 4.00000e+00\n",
      "  1.10000e+01 0.00000e+00 6.00000e+00 1.00000e+00 3.90000e+01]\n",
      " [5.30000e+01 2.34721e+05 0.00000e+00 0.00000e+00 4.00000e+01 4.00000e+00\n",
      "  1.00000e+00 2.00000e+00 6.00000e+00 1.00000e+00 3.90000e+01]\n",
      " [2.80000e+01 3.38409e+05 0.00000e+00 0.00000e+00 4.00000e+01 4.00000e+00\n",
      "  9.00000e+00 2.00000e+00 1.00000e+01 0.00000e+00 5.00000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72bf6b48",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m custom_data_input_dict = {\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mage\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[38;5;28;43mself\u001b[39;49m.age],\n\u001b[32m      3\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mworkclass\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[38;5;28mself\u001b[39m.workclass],\n\u001b[32m      4\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfnlwgt\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[38;5;28mself\u001b[39m.fnlwgt],\n\u001b[32m      5\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33meducation\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[38;5;28mself\u001b[39m.education],\n\u001b[32m      6\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmarital-status\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[38;5;28mself\u001b[39m.marital_status],\n\u001b[32m      7\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33moccupation\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[38;5;28mself\u001b[39m.occupation],\n\u001b[32m      8\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33msex\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[38;5;28mself\u001b[39m.sex],\n\u001b[32m      9\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mcapital-gain\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[38;5;28mself\u001b[39m.capital_gain],\n\u001b[32m     10\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mcapital-loss\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[38;5;28mself\u001b[39m.capital_loss],\n\u001b[32m     11\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mhours-per-week\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[38;5;28mself\u001b[39m.hours_per_week],\n\u001b[32m     12\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mcountry\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[38;5;28mself\u001b[39m.country]\n\u001b[32m     13\u001b[39m             }\n\u001b[32m     15\u001b[39m desired_order = [\n\u001b[32m     16\u001b[39m                 \u001b[33m'\u001b[39m\u001b[33mage\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mfnlwgt\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcapital-gain\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcapital-loss\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mhours-per-week\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     17\u001b[39m                 \u001b[33m'\u001b[39m\u001b[33mworkclass\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33meducation\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmarital-status\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33moccupation\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msex\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcountry\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     18\u001b[39m             ]\n\u001b[32m     20\u001b[39m             \u001b[38;5;66;03m# Reorder the dictionary\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "custom_data_input_dict = {\n",
    "                \"age\": [self.age],\n",
    "                \"workclass\": [self.workclass],\n",
    "                \"fnlwgt\": [self.fnlwgt],\n",
    "                \"education\": [self.education],\n",
    "                \"marital-status\": [self.marital_status],\n",
    "                \"occupation\": [self.occupation],\n",
    "                \"sex\": [self.sex],\n",
    "                \"capital-gain\": [self.capital_gain],\n",
    "                \"capital-loss\": [self.capital_loss],\n",
    "                \"hours-per-week\": [self.hours_per_week],\n",
    "                \"country\": [self.country]\n",
    "            }\n",
    "\n",
    "desired_order = [\n",
    "                'age', 'fnlwgt', 'capital-gain', 'capital-loss', 'hours-per-week',\n",
    "                'workclass', 'education', 'marital-status', 'occupation', 'sex', 'country'\n",
    "            ]\n",
    "\n",
    "            # Reorder the dictionary\n",
    "ordered_data = {key: custom_data_input_dict[key] for key in desired_order if key in custom_data_input_dict}\n",
    "\n",
    "            # Convert to DataFrame if needed\n",
    "           \n",
    "df=pd.DataFrame(ordered_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bc597b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mlops_ineuron",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
